{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lawry\\AppData\\Local\\Temp\\ipykernel_23024\\3495072123.py:5: DtypeWarning: Columns (19,59,129,130,131,134,135,136,139) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
      "0  68407277        NaN     3600.0       3600.0           3600.0   36 months   \n",
      "1  68355089        NaN    24700.0      24700.0          24700.0   36 months   \n",
      "2  68341763        NaN    20000.0      20000.0          20000.0   60 months   \n",
      "3  66310712        NaN    35000.0      35000.0          35000.0   60 months   \n",
      "4  68476807        NaN    10400.0      10400.0          10400.0   60 months   \n",
      "\n",
      "   int_rate  installment grade sub_grade  ... hardship_payoff_balance_amount  \\\n",
      "0     13.99       123.03     C        C4  ...                            NaN   \n",
      "1     11.99       820.28     C        C1  ...                            NaN   \n",
      "2     10.78       432.66     B        B4  ...                            NaN   \n",
      "3     14.85       829.90     C        C5  ...                            NaN   \n",
      "4     22.45       289.91     F        F1  ...                            NaN   \n",
      "\n",
      "  hardship_last_payment_amount disbursement_method  debt_settlement_flag  \\\n",
      "0                          NaN                Cash                     N   \n",
      "1                          NaN                Cash                     N   \n",
      "2                          NaN                Cash                     N   \n",
      "3                          NaN                Cash                     N   \n",
      "4                          NaN                Cash                     N   \n",
      "\n",
      "  debt_settlement_flag_date settlement_status settlement_date  \\\n",
      "0                       NaN               NaN             NaN   \n",
      "1                       NaN               NaN             NaN   \n",
      "2                       NaN               NaN             NaN   \n",
      "3                       NaN               NaN             NaN   \n",
      "4                       NaN               NaN             NaN   \n",
      "\n",
      "  settlement_amount settlement_percentage settlement_term  \n",
      "0               NaN                   NaN             NaN  \n",
      "1               NaN                   NaN             NaN  \n",
      "2               NaN                   NaN             NaN  \n",
      "3               NaN                   NaN             NaN  \n",
      "4               NaN                   NaN             NaN  \n",
      "\n",
      "[5 rows x 151 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "file_path = 'lc_14to16.csv'  # Update with the correct path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to get an overview\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 1091131 rows and 151 columns.\n",
      "                 id  member_id     loan_amnt   funded_amnt  funded_amnt_inv  \\\n",
      "count  1.091131e+06        0.0  1.091131e+06  1.091131e+06     1.091131e+06   \n",
      "mean   5.814955e+07        NaN  1.495881e+04  1.495878e+04     1.495290e+04   \n",
      "std    2.444354e+07        NaN  8.716084e+03  8.716085e+03     8.713271e+03   \n",
      "min    5.571600e+04        NaN  1.000000e+03  1.000000e+03     7.750000e+02   \n",
      "25%    4.021801e+07        NaN  8.000000e+03  8.000000e+03     8.000000e+03   \n",
      "50%    6.147308e+07        NaN  1.305000e+04  1.305000e+04     1.302500e+04   \n",
      "75%    7.717113e+07        NaN  2.000000e+04  2.000000e+04     2.000000e+04   \n",
      "max    9.645316e+07        NaN  4.000000e+04  4.000000e+04     4.000000e+04   \n",
      "\n",
      "           int_rate   installment    annual_inc           dti   delinq_2yrs  \\\n",
      "count  1.091131e+06  1.091131e+06  1.091131e+06  1.091066e+06  1.091131e+06   \n",
      "mean   1.302811e+01  4.428704e+02  7.751796e+04  1.879634e+01  3.520109e-01   \n",
      "std    4.594463e+00  2.554981e+02  7.181074e+04  9.360157e+00  9.301704e-01   \n",
      "min    5.320000e+00  1.401000e+01  0.000000e+00 -1.000000e+00  0.000000e+00   \n",
      "25%    9.490000e+00  2.581000e+02  4.700000e+04  1.235000e+01  0.000000e+00   \n",
      "50%    1.269000e+01  3.815500e+02  6.500000e+04  1.823000e+01  0.000000e+00   \n",
      "75%    1.561000e+01  5.839100e+02  9.200000e+04  2.480000e+01  0.000000e+00   \n",
      "max    3.099000e+01  1.584900e+03  9.573072e+06  9.990000e+02  3.900000e+01   \n",
      "\n",
      "       ...  deferral_term  hardship_amount  hardship_length  hardship_dpd  \\\n",
      "count  ...         7572.0      7572.000000           7572.0   7572.000000   \n",
      "mean   ...            3.0       139.023246              3.0     13.969361   \n",
      "std    ...            0.0       115.402085              0.0      9.709578   \n",
      "min    ...            3.0         0.640000              3.0      0.000000   \n",
      "25%    ...            3.0        52.955000              3.0      6.000000   \n",
      "50%    ...            3.0       107.510000              3.0     15.000000   \n",
      "75%    ...            3.0       190.132500              3.0     23.000000   \n",
      "max    ...            3.0       769.030000              3.0     37.000000   \n",
      "\n",
      "       orig_projected_additional_accrued_interest  \\\n",
      "count                                 5954.000000   \n",
      "mean                                   406.504122   \n",
      "std                                    335.049453   \n",
      "min                                      1.920000   \n",
      "25%                                    155.310000   \n",
      "50%                                    313.650000   \n",
      "75%                                    557.557500   \n",
      "max                                   2307.090000   \n",
      "\n",
      "       hardship_payoff_balance_amount  hardship_last_payment_amount  \\\n",
      "count                     7572.000000                   7572.000000   \n",
      "mean                     10486.839839                    184.214666   \n",
      "std                       6817.138557                    187.290602   \n",
      "min                         55.730000                      0.010000   \n",
      "25%                       5073.072500                     42.927500   \n",
      "50%                       9085.635000                    126.810000   \n",
      "75%                      14568.247500                    268.575000   \n",
      "max                      36605.830000                   1407.860000   \n",
      "\n",
      "       settlement_amount  settlement_percentage  settlement_term  \n",
      "count       27193.000000           27193.000000     27193.000000  \n",
      "mean         4874.077188              47.365733        13.090097  \n",
      "std          3555.105553               6.836303         7.813901  \n",
      "min            44.210000               0.450000         0.000000  \n",
      "25%          2122.000000              45.000000         6.000000  \n",
      "50%          4082.000000              45.000000        12.000000  \n",
      "75%          6727.000000              50.000000        18.000000  \n",
      "max         30000.000000             521.350000       112.000000  \n",
      "\n",
      "[8 rows x 115 columns]\n",
      "id                             0\n",
      "member_id                1091131\n",
      "loan_amnt                      0\n",
      "funded_amnt                    0\n",
      "funded_amnt_inv                0\n",
      "                          ...   \n",
      "settlement_status        1063938\n",
      "settlement_date          1063938\n",
      "settlement_amount        1063938\n",
      "settlement_percentage    1063938\n",
      "settlement_term          1063938\n",
      "Length: 151, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the size of the dataset\n",
    "print(f\"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "\n",
    "# Display basic statistics of numerical columns\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    36\n",
      "1    36\n",
      "2    60\n",
      "3    60\n",
      "4    60\n",
      "Name: term, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['term'] = df['term'].str.strip().str.replace(' months', '').astype(int)\n",
    "\n",
    "# Now, the 'term' column contains only integers like 36 and 60\n",
    "print(df['term'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "df = df.drop(['id', 'member_id', 'url'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                 0.000000\n",
      "funded_amnt               0.000000\n",
      "funded_amnt_inv           0.000000\n",
      "term                      0.000000\n",
      "int_rate                  0.000000\n",
      "                           ...    \n",
      "settlement_status        97.507815\n",
      "settlement_date          97.507815\n",
      "settlement_amount        97.507815\n",
      "settlement_percentage    97.507815\n",
      "settlement_term          97.507815\n",
      "Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "missing_values = df.isnull().sum() / len(df) * 100\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_amnt  funded_amnt  funded_amnt_inv  term  int_rate  installment grade  \\\n",
      "0     3600.0       3600.0           3600.0    36     13.99       123.03     C   \n",
      "1    24700.0      24700.0          24700.0    36     11.99       820.28     C   \n",
      "2    20000.0      20000.0          20000.0    60     10.78       432.66     B   \n",
      "3    35000.0      35000.0          35000.0    60     14.85       829.90     C   \n",
      "4    10400.0      10400.0          10400.0    60     22.45       289.91     F   \n",
      "\n",
      "  sub_grade                    emp_title emp_length  ... percent_bc_gt_75  \\\n",
      "0        C4                      leadman  10+ years  ...              0.0   \n",
      "1        C1                     Engineer  10+ years  ...              7.7   \n",
      "2        B4                 truck driver  10+ years  ...             50.0   \n",
      "3        C5  Information Systems Officer  10+ years  ...              0.0   \n",
      "4        F1          Contract Specialist    3 years  ...             60.0   \n",
      "\n",
      "   pub_rec_bankruptcies tax_liens tot_hi_cred_lim total_bal_ex_mort  \\\n",
      "0                   0.0       0.0        178050.0            7746.0   \n",
      "1                   0.0       0.0        314017.0           39475.0   \n",
      "2                   0.0       0.0        218418.0           18696.0   \n",
      "3                   0.0       0.0        381215.0           52226.0   \n",
      "4                   0.0       0.0        439570.0           95768.0   \n",
      "\n",
      "  total_bc_limit total_il_high_credit_limit hardship_flag disbursement_method  \\\n",
      "0         2400.0                    13734.0             N                Cash   \n",
      "1        79300.0                    24667.0             N                Cash   \n",
      "2         6200.0                    14877.0             N                Cash   \n",
      "3        62500.0                    18000.0             N                Cash   \n",
      "4        20300.0                    88097.0             N                Cash   \n",
      "\n",
      "  debt_settlement_flag  \n",
      "0                    N  \n",
      "1                    N  \n",
      "2                    N  \n",
      "3                    N  \n",
      "4                    N  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[:, missing_values < 50]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable 'grade'\n",
    "encoder = LabelEncoder()\n",
    "df['grade_encoded'] = encoder.fit_transform(df['grade'])\n",
    "\n",
    "# Drop the original 'grade' column\n",
    "loan_data = df.drop('grade', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert all object-type columns to numeric using LabelEncoder\n",
    "label_encoders = {}\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le  # Store the encoders for future use (inverse transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoding for categorical variables\n",
    "df = pd.get_dummies(df, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                     float64\n",
      "funded_amnt                   float64\n",
      "funded_amnt_inv               float64\n",
      "term                            int64\n",
      "int_rate                      float64\n",
      "                               ...   \n",
      "total_il_high_credit_limit    float64\n",
      "hardship_flag                   int64\n",
      "disbursement_method             int64\n",
      "debt_settlement_flag            int64\n",
      "grade_encoded                   int64\n",
      "Length: 93, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)  # Ensure all columns are now numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dti                           65\n",
      "inq_last_6mths                 1\n",
      "mths_since_last_delinq    524671\n",
      "revol_util                   551\n",
      "avg_cur_bal                    6\n",
      "bc_open_to_buy             11043\n",
      "bc_util                    11673\n",
      "mo_sin_old_il_acct         31128\n",
      "mths_since_recent_bc       10418\n",
      "mths_since_recent_inq     111774\n",
      "num_rev_accts                  1\n",
      "num_tl_120dpd_2m           48467\n",
      "percent_bc_gt_75           11461\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])  # Display columns with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dti               65\n",
      "inq_last_6mths     1\n",
      "avg_cur_bal        6\n",
      "num_rev_accts      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Identify columns with more than 1000 missing values\n",
    "missing_counts = df.isnull().sum()  # Count missing values per column\n",
    "\n",
    "# Step 2: Filter out columns where missing values are greater than 1000\n",
    "columns_to_drop = missing_counts[missing_counts > 500].index\n",
    "\n",
    "# Step 3: Drop those columns\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Apply KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "df_imputed_scaled = imputer.fit_transform(df_scaled)\n",
    "\n",
    "# Optionally inverse transform to original scale\n",
    "df_imputed = scaler.inverse_transform(df_imputed_scaled)\n",
    "\n",
    "# Convert the NumPy array back to a pandas DataFrame using the original column names\n",
    "df_imputed = pd.DataFrame(df_imputed, columns=df.columns)\n",
    "\n",
    "# Replace the original DataFrame with the imputed one\n",
    "df = df_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(df['grade_encoded'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'grade_encoded' column to integer (if it's float or continuous)\n",
    "df['grade_encoded'] = df['grade_encoded'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure the 'grade_encoded' column is discrete\n",
    "df['grade_encoded'] = df['grade_encoded'].astype(int)\n",
    "\n",
    "# Step 1: Scale the data (assuming you already have missing values imputed)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df.drop('grade_encoded', axis=1))\n",
    "\n",
    "# Step 2: Apply Logistic Regression with an increased max_iter\n",
    "model = LogisticRegression(max_iter=1000)  # Increase iterations to 1000\n",
    "\n",
    "# Step 3: Apply RFE to select the top 10 features\n",
    "rfe = RFE(model, n_features_to_select=10)\n",
    "X_rfe = rfe.fit_transform(df_scaled, df['grade_encoded'])\n",
    "\n",
    "# Step 4: Check the selected features\n",
    "selected_features = df.drop('grade_encoded', axis=1).columns[rfe.support_]\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate',\n",
      "       'installment', 'grade', 'sub_grade', 'issue_d', 'total_rec_int'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lawry\\AppData\\Local\\Temp\\ipykernel_23024\\953284202.py:1: DtypeWarning: Columns (19,59,129,130,131,134,135,136,139) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_full = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "df_full = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116,)\n",
      "(36,)\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = df_full.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_columns = df_full.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(numeric_columns.shape)\n",
    "print(categorical_columns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lawry\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\Users\\Lawry\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "C:\\Users\\Lawry\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "df_full[numeric_columns] = scaler.fit_transform(df_full[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "le = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    df_full[col] = le.fit_transform(df_full[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lawry\\AppData\\Local\\Temp\\ipykernel_23024\\938696781.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  outliers['distance'] = abs(outliers['sum'] - outliers['sum'].median())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (771821, 152)\n",
      "Cleaned dataset shape: (764103, 152)\n",
      "Number of outliers removed: 7718\n"
     ]
    }
   ],
   "source": [
    "# Standardize the specified columns\n",
    "columns_for_outlier_detection = ['dti', 'annual_inc', 'delinq_2yrs']\n",
    "df_outlier = df_full[columns_for_outlier_detection].copy()\n",
    "df_outlier = (df_outlier - df_outlier.mean()) / df_outlier.std()\n",
    "\n",
    "# Sum the standardized columns\n",
    "df_outlier['sum'] = df_outlier.sum(axis=1)\n",
    "\n",
    "# Calculate IQR\n",
    "Q1 = df_outlier['sum'].quantile(0.25)\n",
    "Q3 = df_outlier['sum'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = df_outlier[(df_outlier['sum'] < lower_bound) | (df_outlier['sum'] > upper_bound)]\n",
    "\n",
    "# Calculate the number of rows to remove (1% of total rows)\n",
    "rows_to_remove = int(0.01 * len(df_full))\n",
    "\n",
    "# Sort outliers by their distance from the median\n",
    "outliers['distance'] = abs(outliers['sum'] - outliers['sum'].median())\n",
    "outliers_sorted = outliers.sort_values('distance', ascending=False)\n",
    "\n",
    "# Select the top 1% of outliers\n",
    "outliers_to_remove = outliers_sorted.head(rows_to_remove)\n",
    "\n",
    "# Remove outliers from the original dataframe\n",
    "df_cleaned = df_full[~df_full.index.isin(outliers_to_remove.index)]\n",
    "\n",
    "print(f\"Original dataset shape: {df_full.shape}\")\n",
    "print(f\"Cleaned dataset shape: {df_cleaned.shape}\")\n",
    "print(f\"Number of outliers removed: {len(df_full) - len(df_cleaned)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
